<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Overview</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h2 id=""><img src="https://snap-stanford.github.io/ogb-web/assets/img/OGB_rectangle.png" alt="OSCB text" title="Title"></h2>
<p><a href="https://pypi.org/project/ogb/"><img src="https://img.shields.io/pypi/v/ogb" alt="PyPI"></a>
<a href="https://github.com/snap-stanford/ogb/blob/master/LICENSE"><img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License"></a></p>
<h2 id="overview">Overview</h2>
<p>The Open Graph Benchmark (OGB) is a collection of benchmark datasets, data loaders, and evaluators for graph machine learning. Datasets cover a variety of graph machine learning tasks and real-world applications.
The OGB data loaders are fully compatible with popular graph deep learning frameworks, including <a href="https://pytorch-geometric.readthedocs.io/en/latest/">PyTorch Geometric</a> and <a href="https://www.dgl.ai/">Deep Graph Library (DGL)</a>. They provide automatic dataset downloading, standardized dataset splits, and unified performance evaluation.</p>
<p>OGB aims to provide graph datasets that cover important graph machine learning tasks, diverse dataset scale, and rich domains.</p>
<p><strong>Graph ML Tasks:</strong> We cover three fundamental graph machine learning tasks: prediction at the level of nodes, links, and graphs.</p>
<p><strong>Diverse scale:</strong> Small-scale graph datasets can be processed within a single GPU, while medium- and large-scale graphs might require multiple GPUs or clever sampling/partition techniques.</p>
<p><strong>Rich domains:</strong> Graph datasets come from diverse domains ranging from scientific ones to social/information networks, and also include heterogeneous knowledge graphs.</p>
<p><img src="https://snap-stanford.github.io/ogb-web/assets/img/dataset_overview.png" alt="Image" title="Image"></p>
<p>OGB is an on-going effort, and we are planning to increase our coverage in the future.</p>
<h2 ref=>Installation</h2>
You can install OGB using Python's package manager `pip`.
**If you have previously installed ogb, please make sure you update the version to 1.3.4.**
The release note is available [here](https://github.com/snap-stanford/ogb/releases/tag/1.3.4).
<h4 id="requirements">Requirements</h4>
<ul>
<li>Python&gt;=3.6</li>
<li>PyTorch&gt;=1.6</li>
<li>DGL&gt;=0.5.0 or torch-geometric&gt;=2.0.2</li>
<li>Numpy&gt;=1.16.0</li>
<li>pandas&gt;=0.24.0</li>
<li>urllib3&gt;=1.24.0</li>
<li>scikit-learn&gt;=0.20.0</li>
<li>outdated&gt;=0.2.0</li>
</ul>
<h4 id="pip-install">Pip install</h4>
<p>The recommended way to install OGB is using Python's package manager pip:</p>
<pre><code class="language-python">pip install ogb

python -c <span class="hljs-string">&quot;import ogb; print(ogb.__version__)&quot;</span>
<span class="hljs-comment"># This should print &quot;1.3.4&quot;. Otherwise, please update the version by</span>
pip install -U ogb
</code></pre>
<h4 id="from-source">From source</h4>
<p>You can also install OGB from source. This is recommended if you want to contribute to OGB.</p>
<pre><code class="language-bash">git <span class="hljs-built_in">clone</span> https://github.com/snap-stanford/ogb
<span class="hljs-built_in">cd</span> ogb
pip install -e .
</code></pre>
<h2 id="package-usage">Package Usage</h2>
<p>We highlight two key features of OGB, namely, (1) easy-to-use data loaders, and (2) standardized evaluators.</p>
<h4 id="1-data-loaders">(1) Data loaders</h4>
<p>We prepare easy-to-use PyTorch Geometric and DGL data loaders. We handle dataset downloading as well as standardized dataset splitting.
Below, on PyTorch Geometric, we see that a few lines of code is sufficient to prepare and split the dataset! Needless to say, you can enjoy the same convenience for DGL!</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> ogb.graphproppred <span class="hljs-keyword">import</span> PygGraphPropPredDataset
<span class="hljs-keyword">from</span> torch_geometric.loader <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-comment"># Download and process data at &#x27;./dataset/ogbg_molhiv/&#x27;</span>
dataset = PygGraphPropPredDataset(name = <span class="hljs-string">&#x27;ogbg-molhiv&#x27;</span>)

split_idx = dataset.get_idx_split() 
train_loader = DataLoader(dataset[split_idx[<span class="hljs-string">&#x27;train&#x27;</span>]], batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">True</span>)
valid_loader = DataLoader(dataset[split_idx[<span class="hljs-string">&#x27;valid&#x27;</span>]], batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">False</span>)
test_loader = DataLoader(dataset[split_idx[<span class="hljs-string">&#x27;test&#x27;</span>]], batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-literal">False</span>)
</code></pre>
<h4 id="2-evaluators">(2) Evaluators</h4>
<p>We also prepare standardized evaluators for easy evaluation and comparison of different methods. The evaluator takes <code>input_dict</code> (a dictionary whose format is specified in <code>evaluator.expected_input_format</code>) as input, and returns a dictionary storing the performance metric appropriate for the given dataset.
The standardized evaluation protocol allows researchers to reliably compare their methods.</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> ogb.graphproppred <span class="hljs-keyword">import</span> Evaluator

evaluator = Evaluator(name = <span class="hljs-string">&#x27;ogbg-molhiv&#x27;</span>)
<span class="hljs-comment"># You can learn the input and output format specification of the evaluator as follows.</span>
<span class="hljs-comment"># print(evaluator.expected_input_format) </span>
<span class="hljs-comment"># print(evaluator.expected_output_format) </span>
input_dict = {<span class="hljs-string">&#x27;y_true&#x27;</span>: y_true, <span class="hljs-string">&#x27;y_pred&#x27;</span>: y_pred}
result_dict = evaluator.<span class="hljs-built_in">eval</span>(input_dict) <span class="hljs-comment"># E.g., {&#x27;rocauc&#x27;: 0.7321}</span>
</code></pre>
<h2 id="citing-ogb--ogb-lsc">Citing OGB / OGB-LSC</h2>
<p>If you use OGB or <a href="https://ogb.stanford.edu/docs/lsc/">OGB-LSC</a> datasets in your work, please cite our papers (Bibtex below).</p>
<pre><code>@article{hu2020ogb,
  title={Open Graph Benchmark: Datasets for Machine Learning on Graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={arXiv preprint arXiv:2005.00687},
  year={2020}
}
</code></pre>
<pre><code>@article{hu2021ogblsc,
  title={OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs},
  author={Hu, Weihua and Fey, Matthias and Ren, Hongyu and Nakata, Maho and Dong, Yuxiao and Leskovec, Jure},
  journal={arXiv preprint arXiv:2103.09430},
  year={2021}
}
</code></pre>

        
        
    </body>
    </html>